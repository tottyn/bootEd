---
title: "Constructing  Bootstrap Intervals"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Constructing  Bootstrap Intervals}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: ref.bib
citation_package: biblatex
biblatexoptions: [style = authoryear, maxcitenames = 2, uniquelist = false]
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#",
  echo = TRUE,
  error = FALSE,
  message = FALSE,
  warning = FALSE,
  fig.width = 5,
  fig.height = 4
)

library(devtools)
load_all()

```

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

## Introduction

When we have an independent random sample that is representative of the population we can implement simple bootstrapping procedures for constructing bootstrap intervals. We will discuss the three main bootstrap intervals which are the basic, percentile, and studentized bootstrap intervals as well as their underlying assumptions. Later we will walk through examples of how to use the package `bootEd` to obtain bootstrap intervals using these methods. 

To install `bootEd` use the following chunk of code: 

```{r, eval = FALSE}

# install devtools in order to use the install_github function (skip if you already have it, comment out once installed)
install.packages(devtools)

# load devtools
library(devtools)

# install bootEd from GitHub
install_github("tottyn/bootEd")

# load bootEd
library(bootEd)

```


## Bootstrap Intervals

To construct a good interval estimate we need to take into account how much uncertainty there is in our point estimate using the variation in sample statistics from sample to sample. The usefulness of bootstrap intervals is most noticeable when the variance of the sample statistic cannot be easily determined because the sampling distribution cannot be obtained or assumptions about the form of the sampling distribution do not hold. However, bootstrap methods do have their own assumptions which should be considered to ensure the validity of results. We now proceed to a brief discussion on these methods and their underlying assumptions. A more in depth discussion on these methods and the theory behind them is given in @davison1997bootstrap. 

<b> Basic Bootstrap Interval </b>

If we denote the $\alpha/2$ and $1-\alpha/2$ quantiles of the distribution of $\hat\theta - \theta$ as $a_{\alpha/2}$ and $a_{1-\alpha/2}$ respectively, then a $(1-\alpha)100\%$ equi-tailed interval for $\theta$ has the form

\begin{equation} 
\label{eq:mainconf}
  (\hat\theta - a_{1 -\alpha/2}, \hat\theta - a_{\alpha/2})
\end{equation}

These quantiles can be estimated through bootstrapping by noting that the $p$-th quantile, $a_p = t_p - \theta$, can be estimated with $a^*_p = t^*_p - \hat\theta$ where $t_p$ and $t^*_p$ are the $p$-th quantiles of the distributions of $\hat\theta$ and $\hat\theta^*$, respectively. Upon substituting these estimates into $\eqref{eq:mainconf}$ we obtain the <i> basic bootstrap interval </i> which is $$(2\hat\theta - t^*_{(B + 1)(1 - \alpha/2)}, 2\hat\theta - t^*_{(B + 1)(\alpha/2)}),$$

where $B$ is the number of bootstrap resamples. The use of the $(B+1)*p$ largest value for the $p$-th quantile is suggested by @davison1997bootstrap as a more reasonable option that the $p$-th quantile. It should be noted that there is substantial coverage error when the distributions of $\hat\theta - \theta$ and $\hat\theta^* - \hat\theta$ differ significantly. 

<b> Percentile Bootstrap Interval </b>

If the distribution of $\hat\theta - \theta$ is symmetric then $-a_{1 -\alpha/2} = a_{\alpha/2}$ and due to the symmetry the bootstrap estimates for $a_{1-\alpha/2}$ and $a_{\alpha/2}$ may be denoted as $a^*_{\alpha/2} = \hat\theta - t^*_{1 -\alpha/2}$ and $a^*_{1-\alpha/2} = \hat\theta - t^*_{\alpha/2}$ where $t^*_p$ is the $p$-th quantile of the distribution of bootstrap sample statistics. Therefore, $\eqref{eq:mainconf}$ becomes $(t^*_{(B+1)(\alpha/2)}, t^*_{(B+1)(1-\alpha/2)})$ and this is the <i> percentile bootstrap interval </i>. The simplicity of this method makes it desirable from a pedagogical standpoint but one should be weary in applying it if the distribution of $\hat\theta$ is not nearly symmetric as it can have low coverage.

<b> Studentized Bootstrap Interval </b>

Using normal approximation a confidence interval for $\theta$ is given as $\hat\theta \pm z_{1-\alpha/2} \sqrt{\hat{\sigma}^2}$. Each of the needed values can be estimated through bootstrapping: the critical value, $z_{1-\alpha/2}$, is estimated with $z^*_p$, the $p$-th quantile of the distribution of $$z^* = \frac{\hat\theta^* - \hat\theta}{\hat{\sigma}^*}$$ where $\hat{\sigma}^*$ is an estimate of the standard deviation of $\hat\theta^*$ and $\hat{\sigma}$ is an estimate for the standard deviation of $\hat\theta$ which uses the bootstrap sample statistics and the original sample statistic. This leads to $(1-\alpha)$ equi-tailed interval of the form $$\left(\hat\theta - z^*_{(B+1)(1-\alpha/2)}\hat{\sigma},~~ \hat\theta - z^*_{(B+1)(\alpha/2)}\hat{\sigma}\right).$$

## Baby Names Example

To implement these methods using `bootEd` we use the dataset `babynames` from the `babynames` package. This dataset contains information on the occurrence of babynames (with at least 5 uses) from the years 1880 to 2017 and is provided by the Social Security Administration (SSA). Note that we are using a dataset that contains information on the entire population so we already know the population parameters. Though this is not usually the case, using data on the entire population will allow us to determine if our interval captures the true parameter value and assess the assumptions that pertain to the population.

The variables included in the entire dataset are:

- year: year of application
- sex: sex of applicant (F = female, M = male)
- name: name of child at birth
- n: total number of applicants with a given name in a given year of a given gender
- prop: n divided by the total number of applicants in that year (proportion of people of that gender with that name of all people born in that year)

Begin by installing and loading the `babynames` package and dataset. 

```{r}

# uncomment the lines of code below to install the babynames package
#install.packages("babynames")

# load the package
library(babynames)

# load the babynames dataset
data("babynames")

# view the documentation for the dataset (uncomment first)
# ?babynames

# view the first six lines of the babynames dataset
head(babynames)

```

If you have trouble installing the `babynames` pacakge using the code above you can also extract it from the `bootEd` package system files using the code below.

```

babynames <- rbind(read.csv(system.file("extdata", "babynames1.csv", package = "bootEd")),
                   read.csv(system.file("extdata", "babynames2.csv", package = "bootEd")),
                   read.csv(system.file("extdata", "babynames3.csv", package = "bootEd")),
                   read.csv(system.file("extdata", "babynames4.csv", package = "bootEd"))
                   )

```

We are interested in eliciting information about the proportion of babies born in the US in 2012 that were female. First we need to subset the dataset and extract information for the year 2012 only. 

```{r}

# subset the entire dataset to only those observations that occured in the year 2012
babies2012 <- babynames[babynames$year == "2012", ]

```

Now notice that the variable `n` contains the number of babies born in the year 2012 with a given name of a given sex. So each row is actually `n` observations, not one observation. Therefore, we actually need to repeat each row `n` times to generate the full dataset. 

```{r}

# determine how many babies total were born in 2012 - this should match the number of rows of the resulting dataset
sum(babies2012$n)

# repeat the index for each row of the dataset n times, where n is different for each row and is given by the variable n
indices <- rep(1:nrow(babies2012), babies2012$n)

# create expanded dataset and drop the columns that contain n (column 4) and prop (column 5)
babies2012expanded <- babies2012[indices,-c(4,5)]

# check that number of rows of expanded dataset matches number of babies born in 2012 found earlier
nrow(babies2012expanded)

```

<hr style="border: 1px dashed black;" />

<b> Check for understanding: </b>

1.) What is the random variable? 
<!-- The number of female babies. -->

2.) What is the variable of interest? 
<!-- Whether the baby is male or female. -->

3.) What is the population of interest? 
<!-- The population of interest is all babies born in the US in 2012. -->

4.) What is the parameter of interest? 
<!-- The parameter of interest is the proportion of female babies born in the US in 2012.  -->

5.) What statistic best estimates this parameter of interest?
<!-- The sample proportion is our best estimate at the population proportion if we have a representative sample.  -->

<hr style="border: 1px dashed black;" />

Now that we have the desired subset of our data let us imitate the usual sampling scheme by taking a simple random sample of size 35 from the population of interest supposing that we do not have population data. 

```{r}

# be sure to run this to get the same results
set.seed(8120)

# generate a random sample of 35 indices
sampindices <- sample(1:nrow(babies2012expanded), 35, replace = FALSE)

# subset the dataset using the random sample of indices
babies2012sample <- babies2012expanded[sampindices,]

# view the first six rows of the sample data
head(babies2012sample)

```

What is the proportion of babies born in our sample that were female?

```{r}

# total number of female babies in sample divided by total number of babies in sample
sum(babies2012sample$sex == "F")/length(babies2012sample$sex)

```

If we repeated this process 1000 times would we see similar values? The distribution of sample proportions from all possible samples of the population is called the sampling distribution of the sample proportion. It would not be computationally feasible to actually generate all possible samples from the population but we can generate 1000 samples and construct an approximate sampling distribution. The code below can be used to do this with a `for` loop.

```{r}

# create an empty vector of length 1000 to save the proportions to
babyprops <- numeric(1000)

for(i in 1:1000){ # repeat 1000 times and save each time
  
  # generate a random sample of 35 indices
  sampindices_loop <- sample(1:nrow(babies2012expanded), 35, replace = FALSE)
  
  # subset the dataset using the random sample of indices
  babies2012sample_loop <- babies2012expanded[sampindices_loop,]
  
  # total number of female babies in sample divided by total number of babies in sample
  babyprops[i] <- sum(babies2012sample_loop$sex == "F")/length(babies2012sample_loop$sex)
  
}

```

The histogram below is the approximate sampling distribution of the sample statistic. It is roughly centered at the population proportion due to the Central Limit Theorem and will be more so as we increase the sample size. 

```{r}

# calculate the population proportion and save

pop_prop <- sum(babies2012expanded$sex == "F")/length(babies2012expanded$sex)

# create the histrogram
hist(babyprops, main = "Sampling Distribution", xlab = "Sample Proportions")

# add a vertical line at the population proportion for reference
abline(v = pop_prop, col = "red", lwd = 2)

```

If we were to use only our sample statistic as a point estimate for the population parameter we would produce highly biased results and ignore much of the information in the population because each sample statistic varies from sample to sample as is evidenced by the histogram above. Therefore, we construct interval estimates, such as bootstrap intervals, to better understand what values are plausible for the population parameter.

With `bootEd` the basic bootstrap interval can be obtained using the `basicMBI` function. First we need to define a function that calculates the proportion because the `parameter` argument of `basicMBI` takes the name of a pre-defined `R` function in quotes. There is no predefined function for calculating proportions in R so we need to define it ourselves.

```{r}

# creating a function that calculates the proportion of females
proportion <- function(x){
  sum(x == "F")/length(x)
}

# checking the function - this should be 0.8
test <- c("F", "F", "F", "F", "M")
proportion(test)

```

<hr style="border: 1px dashed black;" />

<b> Check for understanding: </b>

7.) Which of the following base R functions would given an error if it were specified in the `parameter` argument of the `basicMBI` function? (Hint: run ?percentileMBI and note the requirements of that argument)

<!-- The range function gives the minimum value and maximum value of the vector supplied to it so it returns two values instead of one; not the usual range which is max-min (one number). -->

<ol type = "a">
  <li> `min` </li>
  <li> `range` </li>
  <li> `sd` </li>
</ol>

<hr style="border: 1px dashed black;" />

The function `basicMBI` returns the interval with instructions on what assumptions to consider, a histogram of the bootstrap sample statistics, and a histogram of the shifted bootstrap distribution. For more understanding it is important to pay attention to the labels of these plots and to discuss the assumptions of the method used. It is possible for just the interval to be returned without the histogram or prompt to check assumptions if the argument `onlyint` is set to `TRUE`.

```{r}

# bootstrap interval using the percentile method and original sample taken
basicMBI(sample = babies2012sample$sex, parameter = "proportion", B = 999, siglevel = 0.05)

```

<hr style="border: 1px dashed black;" />

<b> Check for understanding: </b>

8.) Consider the last sentence printed in the output above. For what sample statistic would this assumption hold? That is, for what sample statistic would the shifted sampling distribution be similar to the shifted bootstrap distribution in theory?

<!-- The sampling distribtion of the sample mean is asymptotically normal according to the CLT, the bootstrap distribution of bootstrap sample means will also be approximately normal so we can say that these two are approximately similar according to theory.  -->

9.) How is the red line in the first histogram of the output above different from the red line in the histogram of the sampling distribution created earlier? (Hint: run ?basicMBI and read through the 'Value' section)

<!-- The red line in the sampling distribution is at the population parameter but the red line in the bootstrap distribution is at the sample statistic originally observed. -->

<hr style="border: 1px dashed black;" />

Since we are using population data we can actually make a comparison between the shifted sampling distribution of the sample statistic and the shifted bootstrap distirbution. Recall that we constructed an approximate sampling distribution earlier. After shifting that distribution by the population proportion, in the histogram below, we can compare it to the shifted bootstrap distribution above.

```{r}

# create the histrogram of the shifted sample proportions
hist(babyprops - pop_prop, main = "Shifted Sampling Distribution", xlab = "Sample Proportions - Population proportion")

```

The other methods discussed earlier can also be used to obtain bootstrap intervals in `bootEd`. These are implemented in the functions `percentileMBI` and `studentizedMBI` for the percentile and studentized bootstrap intervals, respectively. The function `percentileMBI` returns the bootstrap interval with a note about checking the assumptions of the method as well as a histogram of the bootstrap sample statistics.

```{r}

percentileMBI(sample = babies2012sample$sex, parameter = "proportion", B = 999, siglevel = 0.05)

```

Similarly, `studentizedMBI` returns the same output as well as a scatterplot of the estimated variance of the bootstrap sample statistic (using a second-level bootstrap) and the bootstrap sample statistic. 

```{r}

studentizedMBI(sample = babies2012sample$sex, parameter = "proportion", B = 999, siglevel = 0.05)

```

The bounds of all the intervals are fairly close to each other and each of them captures the true parameter value. The assumptions of the basic bootstrap interval seem to be met somewhat well when comparing the shifted sampling distribution and the bootstrap distribution. Also, the distribution of bootstrap sample statistics is fairly symmetric so the assumptions of the percentile method are met well. That being said, the scatterplot of bootstrap sample statistics vs. second level bootstrap sample standard errors shows a slight negative trend indicating that the assumptions of the studentized method may not be fully met. We now proceed to a discussion on why checking these assumptions is necessary.

## Why Check Assumptions?

Instructions on assumption checking are included in the output of all `bootEd` functions because when these assumptions are not met the resulting intervals are not valid. In this section we use simulation to demonstrate this in the case of the percentile bootstrap interval. The main assumption for this interval is symmetry in the sampling distribution of the sample statistic. This assumption holds when the statistic of interest is the sample mean or sample proportion due to the Central Limit Theorem but for certain statistics it does not hold. For example, suppose that $X_1, X_2, \ldots, X_n$ are distributed $Exponential(2)$ and we are interested in constructing a percentile bootstrap interval for the population variance.In general, the variance of an $Exponential(\lambda)$ random variable is $1/\lambda^2$ and in our case $\lambda = 2$ so $Var(X) = 0.25$ which is the true value of the population parameter. Using simulation, we can construct an approximate sampling distribution of the sample variance when the sample size is 40. 

```{r}

# generate 1000 samples of size 40 from an Exp(2) distribution
expmat <- matrix(rexp(40*1000, 2), nrow = 40, ncol = 1000)

# find the variance of each sample (each column)
exp_vars <- apply(expmat, 2, var)

# plot the sampling distribution of sample variance (approximate sampling distribution)
hist(exp_vars, xlab = "Sample Variance", main = "Sampling Distribution")

```

We see that the sampling distribution is not symmetric. What happens if we ignore the assumptions of the percentile interval and construct an interval for the population variance? Below we obtain the bootstrap distribution and an interval estimate and we see that the interval captures the true parameter.

```{r}

# use just one of the 1000 samples of size 40 from an Exp(2) population
samp <- expmat[, 30]

# construct a percentile bootstrap interval from that one sample
percentileMBI(sample = samp, parameter = "var", B = 999, siglevel = 0.05)

```

What happens if we repeat the process 1000 times for each of the samples that we took from the population? What proportion of intervals will contain the true parameter, that is, what will be the coverage proportion? We see that the coverage proportion below is much lower than what we would expect. Since $\alpha = 0.05$ it should be closer to 0.95. 
```{r}

# create a logical vector to store the results of the loop in
contained <- logical(1000)

for(i in 1:1000){ # repeat 1000 times and save each time
  
  # set the working sample as the ith column of the matrix that had 1000 samples
  samp_loop <- expmat[,i]
  
  # construct an interval using that sample
  interval <- percentileMBI(sample = samp_loop, parameter = "var", B = 999, 
                            siglevel = 0.05, onlyint = TRUE)
  
  # check that 0.25 is within the bounds of the interval - if so this returns TRUE or else it returns FALSE
  contained[i] <- interval[1] <= 0.25 & interval[2] >= 0.25
  
}

# determine the proportion of intervals that contained the true parameter - that is, the proportion of TRUE's
mean(contained)

```

<hr style="border: 1px dashed black;" />

<b> Further Exploration: </b>

10.) If we were to repeat the simulation above using the basic or studentized intervals would we obtain similar results for the coverage proportions? What would happen if we increased our original sample size?

<hr style="border: 1px dashed black;" />

## Conclusions

The bootstrap intervals that we have discussed are widely used in many more complex applications so it is important to have a solid understanding of the underlying ideas. The aim of `bootEd` is to foster a good understanding of the bootstrap intervals discussed while also remembering that there are underlying assumptions to these intervals. In the last example we saw that it is important to check the assumptions of each method as thoroughly as possible in order to ensure valid results. It should also be noted that in the last example the distribution of bootstrap sample statistics was not as skewed as the approximate sampling distribution. Users of the bootstrap should be aware that its estimate of the sampling distribution is not exactly exchangeable with the actual sampling distribution, especially when the assumptions are not met. That being said, when these bootstrap intervals are used correctly they are a powerful tool for quantifying the uncertainty in an estimate and can greatly influence the results of ones analysis in a positive way.  

## References










